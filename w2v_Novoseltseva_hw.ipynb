{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aonovoseltseva/computer_linguistics_25_26/blob/main/w2v_Novoseltseva_hw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом практикуме мы рассмотрим работу с библиотекой **Gensim** для работы с векторными представлениями текста\n",
        "\n",
        "Мы рассмотрим\n",
        "- **Word2Vec** - векторные представления слов\n",
        "- **FastText** - улучшенные представления с учетом морфологии  \n",
        "- **Doc2Vec** - векторные представления документов\n"
      ],
      "metadata": {
        "id": "N4SYal7iVHxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec, FastText, Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bolJ-w-oVVZZ",
        "outputId": "d3939182-eac0-4964-a435-3ec5b454c54b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 1: Word2Vec\n",
        "\n",
        "### Что такое Word2Vec?\n",
        "\n",
        "Word2Vec преобразует слова в векторы чисел так, что семантически похожие слова оказываются близко в векторном пространстве.\n",
        "\n",
        "**Два основных алгоритма:**\n",
        "- **CBOW** - предсказывает слово по контексту\n",
        "- **Skip-gram** - предсказывает контекст по слову\n",
        "\n",
        "**Загрузка предобученной модели**"
      ],
      "metadata": {
        "id": "vB663h2uXJE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = api.load('glove-wiki-gigaword-100')\n",
        "\n",
        "print(f\"Размер словаря: {len(w2v_model.key_to_index)}\")\n",
        "print(f\"Размерность векторов: {w2v_model.vector_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m2YjiqkVVmd",
        "outputId": "faca1417-5148-419f-970b-074dc003cdec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "Размер словаря: 400000\n",
            "Размерность векторов: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите документацию `gensim`: какие датасеты кроме `glove-wiki-gigaword-100` доступны в библиотеке?\n",
        "\n",
        "Выберите 3 датасета и кратко опишите их (источник данных, примерный объем, зачем такой датасет может использоваться)"
      ],
      "metadata": {
        "id": "VDOPbPZCXQJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Базовые операции с векторами**"
      ],
      "metadata": {
        "id": "eib9fIpIXp3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем вектор слова\n",
        "vector = w2v_model['computer']\n",
        "print(f\"Вектор слова 'computer': {vector[:5]}...\")  # Показываем первые 5 чисел\n",
        "\n",
        "# Вычисляем схожесть между словами\n",
        "similarity = w2v_model.similarity('computer', 'laptop')\n",
        "print(f\"Схожесть 'computer' и 'laptop': {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9fBjDYNXoUO",
        "outputId": "bf41f24e-051f-45d3-8355-26c81c7e6e03"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вектор слова 'computer': [-0.16298   0.30141   0.57978   0.066548  0.45835 ]...\n",
            "Схожесть 'computer' и 'laptop': 0.7024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Поиск похожих слов**"
      ],
      "metadata": {
        "id": "Ev1yMPZ8XuI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Находим похожие слова\n",
        "similar_words = w2v_model.most_similar('python', topn=5)\n",
        "print(\"Слова, похожие на 'python':\")\n",
        "for word, score in similar_words:\n",
        "    print(f\"  {word}: {score:.4f}\")"
      ],
      "metadata": {
        "id": "8WkxOy8uXteF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "660ce66e-31ae-4e0c-a3ce-2ff54b00dc99"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слова, похожие на 'python':\n",
            "  monty: 0.6886\n",
            "  php: 0.5865\n",
            "  perl: 0.5784\n",
            "  cleese: 0.5447\n",
            "  flipper: 0.5113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'glove-wiki-gigaword-300'\n",
        "\n",
        "источники: 2024 Wikipedia (база данных на основе разных разделов википедии) + Gigaword 5 (база данных из разных новостных источников)\n",
        "объем: 11.9B tokens, 1.2M vocab, 300d vectors, 1.6 GB download\n",
        "использование: средняя размерность, поэтому обучение моделей для NLP целей, поиск похожих по смыслу списков слов\n",
        "\n",
        "'glove-twitter-25'\n",
        "источники: twitter\n",
        "объем: 2B tweets, 27B tokens, 1.2M vocab, 25d vectors\n",
        "использование: низкая размерность модели ограничивает применение, например, поиском похожих на запрос результатов по ключевым словам\n",
        "\n",
        "'glove-twitter-50'\n",
        "источники: twitter\n",
        "объем: 2B tweets, 27B tokens, 1.2M vocab, 50d vectors\n",
        "использование: поиск похожих товаров, первичная фильтрация*Ваш ответ здесь*"
      ],
      "metadata": {
        "id": "AKeYJM6IXgVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**\n",
        "\n",
        "1. Загрузите любой датасет из gensim на ваш выбор"
      ],
      "metadata": {
        "id": "TM76pHnKXi_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = api.load('glove-twitter-50')"
      ],
      "metadata": {
        "id": "pqblXXpmXOhi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10f7bfa6-21a4-4cce-fa15-5684adbf9a68"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 199.5/199.5MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Напишите функцию, которая принимает на вход любое слово и вовращает 10 наиболее близких по вектору слов"
      ],
      "metadata": {
        "id": "vr2jwkoYXw4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = input('Введите любое слово ')\n",
        "close_words = w2v_model.most_similar(a, topn = 5)\n",
        "print('Близкие по смыслу слова:')\n",
        "for word, score in close_words:\n",
        "  print(f'{word}: {score}')"
      ],
      "metadata": {
        "id": "41PPnrrtX7lp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a86ec84-c191-446d-df51-10bc1976349b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Введите любое слово овощи\n",
            "Близкие по смыслу слова:\n",
            "фрукты: 0.8991486430168152\n",
            "котлеты: 0.7279103994369507\n",
            "татуировки: 0.7276136875152588\n",
            "орехи: 0.7274090647697449\n",
            "напитки: 0.721818745136261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Обучите модель Word2Vec на тестовом датасете из ячейки ниже\n",
        "\n",
        "Примените следующие настройки:\n",
        "\n",
        "- размер вектора: 50\n",
        "- размер окна: 3\n",
        "- минимальная частота слова: 1\n",
        "- потоков: 2\n",
        "- использовать skip-gram"
      ],
      "metadata": {
        "id": "kqb9gAAtX-2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cooking_sentences = [\n",
        "    ['варить', 'суп', 'овощи', 'морковь', 'картофель'],\n",
        "    ['жарить', 'курица', 'сковорода', 'масло', 'специи'],\n",
        "    ['печь', 'хлеб', 'мука', 'дрожжи', 'духовка'],\n",
        "    ['резать', 'овощи', 'салат', 'помидоры', 'огурцы'],\n",
        "    ['смешивать', 'ингредиенты', 'тесто', 'яйца', 'молоко'],\n",
        "    ['варить', 'паста', 'вода', 'соль', 'соус'],\n",
        "    ['гриль', 'мясо', 'овощи', 'уголь', 'барбекю'],\n",
        "    ['тушить', 'говядина', 'горшок', 'вино', 'травы'],\n",
        "    ['запекать', 'рыба', 'лимон', 'духовка', 'фольга'],\n",
        "    ['готовить', 'завтрак', 'яичница', 'бекон', 'тост'],\n",
        "    ['месить', 'тесто', 'пирог', 'начинка', 'яблоки'],\n",
        "    ['кипятить', 'вода', 'чай', 'кофе', 'чашка'],\n",
        "    ['мариновать', 'мясо', 'соус', 'специи', 'холодильник'],\n",
        "    ['взбивать', 'сливки', 'сахар', 'десерт', 'торт'],\n",
        "    ['парить', 'овощи', 'здоровое', 'питание', 'брокколи']\n",
        "]"
      ],
      "metadata": {
        "id": "Hx2_76jlX99p"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model_2 = Word2Vec(\n",
        "    sentences = cooking_sentences,\n",
        "    vector_size = 50,\n",
        "    window = 3,\n",
        "    min_count = 1,\n",
        "    workers = 2,\n",
        "    sg = 1,\n",
        ")"
      ],
      "metadata": {
        "id": "8dnq5WXtt2SI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Слова в словаре: {list(w2v_model_2.wv.key_to_index.keys())[:10]}...\")"
      ],
      "metadata": {
        "id": "uC6KfmGuYUsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2bd380b-90f6-4bc2-fed1-983ce4cd0bd7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слова в словаре: ['овощи', 'мясо', 'соус', 'вода', 'тесто', 'духовка', 'специи', 'варить', 'брокколи', 'питание']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Проверьте модель"
      ],
      "metadata": {
        "id": "rUp76Ko3YYLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверяем похожие слова в кулинарной тематике\n",
        "try:\n",
        "    similar = w2v_model_2.wv.most_similar('варить', topn=5)\n",
        "    print(\"Слова, похожие на 'варить':\")\n",
        "    for word, score in similar:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "except KeyError:\n",
        "    print(\"Слово 'варить' не найдено в словаре\")"
      ],
      "metadata": {
        "id": "NL21ZMMMYZqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "363b7192-e025-4b0c-b901-856a60c97504"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слова, похожие на 'варить':\n",
            "  вино: 0.2398\n",
            "  ингредиенты: 0.2172\n",
            "  хлеб: 0.1938\n",
            "  брокколи: 0.1846\n",
            "  кипятить: 0.1711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Найдите слова, похожие на \"духовка\"\n",
        "try:\n",
        "  similar = w2v_model_2.wv.most_similar('духовка', topn = 5)\n",
        "  print('Похожие на \"духовка\": ')\n",
        "  for word, score in similar:\n",
        "    print(f'{word}: {score}')\n",
        "except KeyError:\n",
        "  print('Слова \"духовка\" нет в словаре')\n",
        "# Найдите слова, похожие на \"овощи\"\n",
        "try:\n",
        "  similar = w2v_model_2.wv.most_similar('овощи', topn = 5)\n",
        "  print('Похожие на \"овощи\": ')\n",
        "  for word, score in similar:\n",
        "    print(f'{word}: {score}')\n",
        "except KeyError:\n",
        "  print('Слова \"овощи\" нет в словаре')"
      ],
      "metadata": {
        "id": "DZWc7eNVYcSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d810a53e-5bd8-4359-b647-369b63430e38"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Похожие на \"духовка\": \n",
            "ингредиенты: 0.3198968470096588\n",
            "десерт: 0.30644166469573975\n",
            "холодильник: 0.27045494318008423\n",
            "питание: 0.22426293790340424\n",
            "пирог: 0.21422232687473297\n",
            "Похожие на \"овощи\": \n",
            "мариновать: 0.2715907096862793\n",
            "хлеб: 0.26912084221839905\n",
            "гриль: 0.25464725494384766\n",
            "фольга: 0.24094568192958832\n",
            "сахар: 0.21084155142307281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 2: FastText"
      ],
      "metadata": {
        "id": "i1JAFNQvYhAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FastText улучшает Word2Vec, рассматривая слова как наборы символов (n-грамм). Это позволяет работать с редкими словами и опечатками"
      ],
      "metadata": {
        "id": "Z1tWdzB-Ysi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Обучите FastText на корпусе текстов из пункта 3. Используйте код ниже"
      ],
      "metadata": {
        "id": "79i4vH8NY-0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model = FastText(\n",
        "    sentences= cooking_sentences,\n",
        "    vector_size=50,\n",
        "    window=3,\n",
        "    min_count=1,\n",
        "    workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "-IrOgMpQYuda"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Найдите слова, похожие на \"варить\", \"духовка\" и \"овощи\" с помощью обученной модели. Используйте код из пункта 4"
      ],
      "metadata": {
        "id": "JBTW3zDPZIIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  similar = ft_model.wv.most_similar('варить', topn = 5)\n",
        "  print('Похожие на \"варить\": ')\n",
        "  for word, score in similar:\n",
        "    print(f'{word}: {score}')\n",
        "except KeyError:\n",
        "  print('Слова \"варить\" нет в словаре')\n",
        "try:\n",
        "  similar = ft_model.wv.most_similar('духовка', topn = 5)\n",
        "  print('Похожие на \"духовка\": ')\n",
        "  for word, score in similar:\n",
        "    print(f'{word}: {score}')\n",
        "except KeyError:\n",
        "  print('Слова \"духовка\" нет в словаре')\n",
        "try:\n",
        "  similar = ft_model.wv.most_similar('овощи', topn = 5)\n",
        "  print('Похожие на \"овощи\": ')\n",
        "  for word, score in similar:\n",
        "    print(f'{word}: {score}')\n",
        "except KeyError:\n",
        "  print('Слова \"овощи\" нет в словаре')"
      ],
      "metadata": {
        "id": "ouc0CcZAY6QG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "634cc52a-74ee-496c-99a3-b57861b96638"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Похожие на \"варить\": \n",
            "жарить: 0.5353310108184814\n",
            "парить: 0.4804992079734802\n",
            "месить: 0.3540874421596527\n",
            "тушить: 0.34048697352409363\n",
            "специи: 0.2621820569038391\n",
            "Похожие на \"духовка\": \n",
            "взбивать: 0.45650428533554077\n",
            "лимон: 0.3561227023601532\n",
            "салат: 0.30499011278152466\n",
            "курица: 0.3041205108165741\n",
            "тост: 0.2943783700466156\n",
            "Похожие на \"овощи\": \n",
            "жарить: 0.29603469371795654\n",
            "фольга: 0.25739818811416626\n",
            "морковь: 0.2296556979417801\n",
            "соус: 0.217234805226326\n",
            "торт: 0.20936326682567596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Сравните модели\n",
        "\n",
        "Дана функция для сравнения Word2Vec и FastText\n",
        "\n",
        "Придумайте 3 слова с опечатками и проверьте, найдет ли их FastText и Word2Vec"
      ],
      "metadata": {
        "id": "vm8kkRlBZYc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models(word):\n",
        "    \"\"\"Сравнивает представления слова в разных моделях\"\"\"\n",
        "    print(f\"\\nСравнение для слова: '{word}'\")\n",
        "\n",
        "    # Word2Vec\n",
        "    try:\n",
        "        w2v_similar = w2v_model_2.wv.most_similar(word, topn=2)\n",
        "        print(f\"  Word2Vec: {[w for w, _ in w2v_similar]}\")\n",
        "    except KeyError:\n",
        "        print(f\"  Word2Vec: слово не найдено\")\n",
        "\n",
        "    # FastText\n",
        "    try:\n",
        "        ft_similar = ft_model.wv.most_similar(word, topn=2)\n",
        "        print(f\"  FastText: {[w for w, _ in ft_similar]}\")\n",
        "    except KeyError:\n",
        "        print(f\"  FastText: слово не найдено\")\n",
        "\n",
        "# Сравниваем для разных слов\n",
        "compare_models('овщи')\n",
        "compare_models('пираг')"
      ],
      "metadata": {
        "id": "3nVH_v9WZY4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c75846a7-fa2e-44c1-e1b6-592092e7ce87"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Сравнение для слова: 'овщи'\n",
            "  Word2Vec: слово не найдено\n",
            "  FastText: ['овощи', 'питание']\n",
            "\n",
            "Сравнение для слова: 'пираг'\n",
            "  Word2Vec: слово не найдено\n",
            "  FastText: ['тост', 'лимон']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 3: Doc2Vec"
      ],
      "metadata": {
        "id": "DP62ewZzZoGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doc2Vec расширяет Word2Vec для создания векторных представлений целых документов (предложений, абзацев, статей)"
      ],
      "metadata": {
        "id": "tG1GNzXcZqOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем размеченные документы\n",
        "documents = [\n",
        "    \"machine learning is interesting\",\n",
        "    \"deep learning uses neural networks\",\n",
        "    \"python programming for data science\",\n",
        "    \"artificial intelligence is amazing\",\n",
        "    \"computer vision processes images\"\n",
        "]\n",
        "\n",
        "# Преобразуем в формат TaggedDocument\n",
        "tagged_docs = []\n",
        "for i, doc in enumerate(documents):\n",
        "    tokens = doc.split()\n",
        "    tagged_doc = TaggedDocument(words=tokens, tags=[f\"doc_{i}\"])\n",
        "    tagged_docs.append(tagged_doc)\n",
        "\n",
        "print(\"Размеченные документы:\")\n",
        "for doc in tagged_docs[:3]:\n",
        "    print(f\"  Слова: {doc.words}\")\n",
        "    print(f\"  Тег: {doc.tags}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_85mtFa_ZxoY",
        "outputId": "1f7faf85-3b39-424a-f5fc-58a7edcae0bc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размеченные документы:\n",
            "  Слова: ['machine', 'learning', 'is', 'interesting']\n",
            "  Тег: ['doc_0']\n",
            "  Слова: ['deep', 'learning', 'uses', 'neural', 'networks']\n",
            "  Тег: ['doc_1']\n",
            "  Слова: ['python', 'programming', 'for', 'data', 'science']\n",
            "  Тег: ['doc_2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучаем Doc2Vec\n",
        "doc_model = Doc2Vec(\n",
        "    documents=tagged_docs,\n",
        "    vector_size=50,\n",
        "    window=3,\n",
        "    min_count=1,\n",
        "    workers=2,\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "print(\"Doc2Vec модель обучена!\")\n",
        "print(f\"Количество документов: {len(doc_model.dv.key_to_index)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HJ1vOcHZx0z",
        "outputId": "55adcab0-68d3-41c8-ee11-b6a50ee47961"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doc2Vec модель обучена!\n",
            "Количество документов: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем вектор документа\n",
        "doc_vector = doc_model.dv[\"doc_0\"]\n",
        "print(f\"Вектор документа doc_0: {doc_vector[:5]}...\")\n",
        "\n",
        "# Находим похожие документы\n",
        "similar_docs = doc_model.dv.most_similar(\"doc_0\", topn=2)\n",
        "print(\"\\nДокументы, похожие на doc_0:\")\n",
        "for doc_tag, similarity in similar_docs:\n",
        "    doc_id = int(doc_tag.split('_')[1])\n",
        "    print(f\"  {doc_tag}: {similarity:.4f}\")\n",
        "    print(f\"    Текст: {documents[doc_id]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x8vHn0bZ0Ow",
        "outputId": "3e7f86bf-2a79-42e4-a1fa-97ad364351e0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вектор документа doc_0: [-0.01057    -0.01198188 -0.01982618  0.01710627  0.00710373]...\n",
            "\n",
            "Документы, похожие на doc_0:\n",
            "  doc_1: 0.2735\n",
            "    Текст: deep learning uses neural networks\n",
            "  doc_2: 0.1275\n",
            "    Текст: python programming for data science\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сравниваем схожесть документов\n",
        "def compare_documents(doc1_id, doc2_id):\n",
        "    similarity = doc_model.dv.similarity(f\"doc_{doc1_id}\", f\"doc_{doc2_id}\")\n",
        "    print(f\"Схожесть doc_{doc1_id} и doc_{doc2_id}: {similarity:.4f}\")\n",
        "    print(f\"  doc_{doc1_id}: {documents[doc1_id]}\")\n",
        "    print(f\"  doc_{doc2_id}: {documents[doc2_id]}\")\n",
        "    return similarity\n",
        "\n",
        "compare_documents(0, 1)  # machine learning vs deep learning\n",
        "compare_documents(0, 3)  # machine learning vs AI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBfjR2xZZ1rC",
        "outputId": "2101ee41-c8ae-4383-edbc-d5216f4303ba"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Схожесть doc_0 и doc_1: 0.2735\n",
            "  doc_0: machine learning is interesting\n",
            "  doc_1: deep learning uses neural networks\n",
            "Схожесть doc_0 и doc_3: -0.0822\n",
            "  doc_0: machine learning is interesting\n",
            "  doc_3: artificial intelligence is amazing\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(-0.08219737)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Сравните схожесть doc_2 и doc_4"
      ],
      "metadata": {
        "id": "1ruGP7-vZ6HS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compare_documents(2, 4)"
      ],
      "metadata": {
        "id": "LujlVE8aZ3fs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41c44dd-49d6-43d3-bb7e-f21fa3dfc381"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Схожесть doc_2 и doc_4: -0.0362\n",
            "  doc_2: python programming for data science\n",
            "  doc_4: computer vision processes images\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(-0.0362442)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Найдите самый похожий документ на doc_1"
      ],
      "metadata": {
        "id": "YkW4U8T_Z_X_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = range(5)\n",
        "max_similarity = -1\n",
        "most_similar_doc = None\n",
        "for i in documents:\n",
        "  if i == 1:\n",
        "    continue\n",
        "  similarity = compare_documents(1, i)\n",
        "  print(f'doc_1 и doc_{i}: {similarity}')\n",
        "  if similarity is not None and similarity > max_similarity:\n",
        "    max_similarity = similarity\n",
        "    most_similar_doc = i\n",
        "print(f'Наиболее схожий документ с doc_1 — doc_{most_similar_doc}, similarity: {max_similarity}')"
      ],
      "metadata": {
        "id": "T0IwRpOPaGX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af96877c-8774-4564-b9c9-8038c16177b1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Схожесть doc_1 и doc_0: 0.2735\n",
            "  doc_1: 1\n",
            "  doc_0: 0\n",
            "doc_1 и doc_0: 0.273516982793808\n",
            "Схожесть doc_1 и doc_2: -0.0573\n",
            "  doc_1: 1\n",
            "  doc_2: 2\n",
            "doc_1 и doc_2: -0.0573110431432724\n",
            "Схожесть doc_1 и doc_3: 0.2031\n",
            "  doc_1: 1\n",
            "  doc_3: 3\n",
            "doc_1 и doc_3: 0.20308849215507507\n",
            "Схожесть doc_1 и doc_4: -0.2546\n",
            "  doc_1: 1\n",
            "  doc_4: 4\n",
            "doc_1 и doc_4: -0.25457313656806946\n",
            "Наиболее схожий документ с doc_1 — doc_0, similarity: 0.273516982793808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Выберите любую из трёх моделей. Обучите модели с разной размерностью (10, 50, 100). Продемонстрируйте качество их работы на примере поиска похожих слов (выберите любые 3 примера, соответствующих тематике корпуса из пункта 4)"
      ],
      "metadata": {
        "id": "GHoOQmGraGmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "documents = [\n",
        "    \"machine learning is interesting\",\n",
        "    \"deep learning uses neural networks\",\n",
        "    \"python programming for data science\",\n",
        "    \"artificial intelligence is amazing\",\n",
        "    \"computer vision processes images\"\n",
        "]\n",
        "\n",
        "documents_tokenized = [word_tokenize(doc.lower()) for doc in documents]\n",
        "\n",
        "model_10 = FastText(\n",
        "    sentences= documents_tokenized,\n",
        "    vector_size=10,\n",
        "    window=3,\n",
        "    min_count=1,\n",
        "    workers=2\n",
        ")\n",
        "model_50 = FastText(\n",
        "    sentences= documents_tokenized,\n",
        "    vector_size=50,\n",
        "    window=3,\n",
        "    min_count=1,\n",
        "    workers=2\n",
        ")\n",
        "model_100 = FastText(\n",
        "    sentences= documents_tokenized,\n",
        "    vector_size=100,\n",
        "    window=3,\n",
        "    min_count=1,\n",
        "    workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "tidpF7AIaXzc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bff0b08-06a4-413d-9db0-396b69652ecb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models_ft(word_1, word_2, word_3):\n",
        "    \"\"\"Сравнивает представления слов в моделях FastText размерностей 10, 50, 100\"\"\"\n",
        "# Сравнение для первого слова\n",
        "    print(f\"\\nСравнение для слова: '{word_1}'\")\n",
        "\n",
        "#10\n",
        "    try:\n",
        "        model_10_similar = model_10.wv.most_similar(word_1, topn=2)\n",
        "        print(f\"  FastText10: {[w for w, _ in model_10_similar]}\")\n",
        "    except KeyError:\n",
        "        print(f\"  FastText10: слово не найдено\")\n",
        "#50\n",
        "    try:\n",
        "        model_50_similar = model_50.wv.most_similar(word_1, topn=2)\n",
        "        print(f\"  FastText50: {[w for w, _ in model_50_similar]}\")\n",
        "    except KeyError:\n",
        "        print(f\"  FastText50: слово не найдено\")\n",
        "#100\n",
        "    try:\n",
        "        model_100_similar = model_100.wv.most_similar(word_1, topn=2)\n",
        "        print(f\"  FastText100: {[w for w, _ in model_100_similar]}\")\n",
        "    except KeyError:\n",
        "        print(f\"  FastText100: слово не найдено\")\n",
        "        print(f\"\\nСравнение для слова: '{word_1}'\")\n",
        "\n",
        "# Сравнение для второго слова\n",
        "\n",
        "    print(f\"\\nСравнение для слова: '{word_2}'\")\n",
        "\n",
        "#10\n",
        "    try:\n",
        "        model_10_similar = model_10.wv.most_similar(word_2, topn=2)\n",
        "        print(f\"  FastText10: {[w for w, _ in model_10_similar]}\")\n",
        "    except KeyError:\n",
        "        print(f\"  FastText10: слово не найдено\")\n",
        "#50\n",
        "    try:\n",
        "        model_50_similar  = model_50.wv.most_similar(word_2, topn=2)\n",
        "        print(f\"  FastText50: {[w for w, _ in model_50_similar]}\")\n",
        "    except KeyError:\n",
        "        print(f\"  FastText50: слово не найдено\")\n",
        "#100\n",
        "    try:\n",
        "        model_100_similar  = model_100.wv.most_similar(word_2, topn=2)\n",
        "        print(f\"  FastText100: {[w for w, _ in model_100_similar]}\")\n",
        "    except KeyError:\n",
        "        print(f\"  FastText100: слово не найдено\")\n",
        "        print(f\"\\nСравнение для слова: '{word_1}'\")\n",
        "\n",
        "# Сравнение для третьего слова\n",
        "\n",
        "    print(f\"\\nСравнение для слова: '{word_3}'\")\n",
        "\n",
        "#10\n",
        "    try:\n",
        "        model_10_similar = model_10.wv.most_similar(word_3, topn=2)\n",
        "        print(f\"  FastText10: {[w for w, _ in model_10_similar]}\")\n",
        "    except KeyError:\n",
        "        print(f\"  FastText10: слово не найдено\")\n",
        "#50\n",
        "    try:\n",
        "        model_50_similar = model_50.wv.most_similar(word_3, topn=2)\n",
        "        print(f\"  FastText50: {[w for w, _ in model_50_similar]}\")\n",
        "    except KeyError:\n",
        "        print(f\"  FastText50: слово не найдено\")\n",
        "#100\n",
        "    try:\n",
        "        model_100_similar = model_100.wv.most_similar(word_3, topn=2)\n",
        "        print(f\"  FastText100: {[w for w, _ in model_100_similar]}\")\n",
        "    except KeyError:\n",
        "        print(f\"  FastText100: слово не найдено\")\n",
        "# Сравниваем для разных слов\n",
        "compare_models_ft('learning', 'deep', 'networks')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0btlANr_2STL",
        "outputId": "53b9fb78-10e5-431d-d44a-8ee709bb6cc9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Сравнение для слова: 'learning'\n",
            "  FastText10: ['images', 'processes']\n",
            "  FastText50: ['programming', 'amazing']\n",
            "  FastText100: ['amazing', 'computer']\n",
            "\n",
            "Сравнение для слова: 'deep'\n",
            "  FastText10: ['data', 'amazing']\n",
            "  FastText50: ['artificial', 'vision']\n",
            "  FastText100: ['networks', 'interesting']\n",
            "\n",
            "Сравнение для слова: 'networks'\n",
            "  FastText10: ['python', 'images']\n",
            "  FastText50: ['neural', 'is']\n",
            "  FastText100: ['science', 'deep']\n"
          ]
        }
      ]
    }
  ]
}